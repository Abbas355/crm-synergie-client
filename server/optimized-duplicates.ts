/**
 * SYST√àME DE GESTION DES DOUBLONS OPTIMIS√â - SINGLE SOURCE OF TRUTH
 * √âlimination des comparaisons multiples inefficaces
 */

import { db } from "../db/index.js";
import { sql } from "drizzle-orm";
import memoize from "memoizee";

interface DuplicateGroup {
  key: string;
  field: string;
  clients: Array<{
    id: number;
    prenom: string;
    nom: string;
    email?: string;
    telephone?: string;
    dateSignature?: string;
  }>;
  count: number;
}

/**
 * D√âTECTION DE DOUBLONS ULTRA-OPTIMIS√âE
 * Une seule requ√™te SQL pour tous les types de doublons possibles
 */
const detectOptimizedDuplicates = memoize(
  async (): Promise<DuplicateGroup[]> => {
    console.log("üöÄ D√âTECTION DOUBLONS OPTIMIS√âE - Single Source of Truth");

    try {
      // **UNE SEULE REQU√äTE POUR TOUS LES TYPES DE DOUBLONS**
      const duplicatesResult = await db.execute(sql`
        WITH potential_duplicates AS (
          SELECT 
            c.id,
            c.prenom,
            c.nom,
            c.email,
            c.telephone,
            c."dateSignature",
            -- ‚úÖ D√âTECTION DOUBLONS EMAIL (normalis√©)
            LOWER(TRIM(c.email)) as normalized_email,
            -- ‚úÖ D√âTECTION DOUBLONS T√âL√âPHONE (normalis√©)  
            REGEXP_REPLACE(c.telephone, '[^0-9]', '', 'g') as normalized_phone,
            -- ‚úÖ D√âTECTION DOUBLONS NOM COMPLET (normalis√©)
            LOWER(TRIM(c.prenom)) || '_' || LOWER(TRIM(c.nom)) as normalized_name
          FROM clients c
          WHERE c."deletedAt" IS NULL
            AND (c.email IS NOT NULL OR c.telephone IS NOT NULL)
        ),
        email_duplicates AS (
          SELECT 
            'email' as field_type,
            normalized_email as duplicate_key,
            COUNT(*) as duplicate_count,
            JSON_AGG(
              JSON_BUILD_OBJECT(
                'id', id,
                'prenom', prenom,
                'nom', nom,
                'email', email,
                'telephone', telephone,
                'dateSignature', "dateSignature"
              )
            ) as clients_data
          FROM potential_duplicates
          WHERE normalized_email IS NOT NULL 
            AND normalized_email != ''
          GROUP BY normalized_email
          HAVING COUNT(*) > 1
        ),
        phone_duplicates AS (
          SELECT 
            'telephone' as field_type,
            normalized_phone as duplicate_key,
            COUNT(*) as duplicate_count,
            JSON_AGG(
              JSON_BUILD_OBJECT(
                'id', id,
                'prenom', prenom,
                'nom', nom,
                'email', email,
                'telephone', telephone,
                'dateSignature', "dateSignature"
              )
            ) as clients_data
          FROM potential_duplicates
          WHERE normalized_phone IS NOT NULL 
            AND normalized_phone != ''
            AND LENGTH(normalized_phone) >= 8
          GROUP BY normalized_phone
          HAVING COUNT(*) > 1
        ),
        name_duplicates AS (
          SELECT 
            'nom_complet' as field_type,
            normalized_name as duplicate_key,
            COUNT(*) as duplicate_count,
            JSON_AGG(
              JSON_BUILD_OBJECT(
                'id', id,
                'prenom', prenom,
                'nom', nom,
                'email', email,
                'telephone', telephone,
                'dateSignature', "dateSignature"
              )
            ) as clients_data
          FROM potential_duplicates
          WHERE prenom IS NOT NULL 
            AND nom IS NOT NULL
            AND TRIM(prenom) != ''
            AND TRIM(nom) != ''
          GROUP BY normalized_name
          HAVING COUNT(*) > 1
        )
        SELECT * FROM email_duplicates
        UNION ALL
        SELECT * FROM phone_duplicates  
        UNION ALL
        SELECT * FROM name_duplicates
        ORDER BY duplicate_count DESC, field_type ASC
      `);

      const duplicateGroups: DuplicateGroup[] = duplicatesResult.rows.map((row: any) => ({
        key: row.duplicate_key,
        field: row.field_type,
        clients: row.clients_data,
        count: parseInt(row.duplicate_count)
      }));

      console.log(`‚úÖ DOUBLONS D√âTECT√âS OPTIMIS√âS : ${duplicateGroups.length} groupes trouv√©s`);
      
      return duplicateGroups;

    } catch (error) {
      console.error("‚ùå Erreur d√©tection doublons optimis√©e:", error);
      return [];
    }
  },
  {
    // ‚úÖ CACHE 10 MINUTES - Doublons √©voluent lentement
    maxAge: 10 * 60 * 1000,
    preFetch: true,
  }
);

/**
 * FUSION AUTOMATIQUE DE DOUBLONS OPTIMIS√âE
 * Logique intelligente de pr√©servation des donn√©es
 */
async function mergeOptimizedDuplicates(
  primaryId: number, 
  duplicateIds: number[]
): Promise<boolean> {
  console.log(`üöÄ FUSION OPTIMIS√âE - Client ${primaryId} ‚Üê [${duplicateIds.join(', ')}]`);

  try {
    await db.transaction(async (tx) => {
      // ‚úÖ 1. MISE √Ä JOUR R√âF√âRENCES CARTES SIM
      await tx.execute(sql`
        UPDATE sim_cards 
        SET "clientId" = ${primaryId}
        WHERE "clientId" = ANY(${duplicateIds})
      `);

      // ‚úÖ 2. MISE √Ä JOUR R√âF√âRENCES T√ÇCHES  
      await tx.execute(sql`
        UPDATE tasks
        SET "clientId" = ${primaryId}
        WHERE "clientId" = ANY(${duplicateIds})
      `);

      // ‚úÖ 3. SUPPRESSION LOGIQUE DES DOUBLONS
      await tx.execute(sql`
        UPDATE clients
        SET "deletedAt" = NOW(),
            "deletedBy" = 'AUTO_MERGE'
        WHERE id = ANY(${duplicateIds})
      `);
    });

    console.log(`‚úÖ FUSION R√âUSSIE - ${duplicateIds.length} doublons fusionn√©s`);
    
    // Invalider le cache pour re-calcul imm√©diat
    detectOptimizedDuplicates.clear();
    
    return true;

  } catch (error) {
    console.error("‚ùå Erreur fusion optimis√©e:", error);
    return false;
  }
}

export { detectOptimizedDuplicates, mergeOptimizedDuplicates };